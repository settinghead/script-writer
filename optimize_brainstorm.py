#!/usr/bin/env python3
"""
Brainstorm optimization script
Uses DSPy optimizers to improve story idea generation quality
"""

import mlflow
from copy import copy
from typing import List
import dspy
from dspy.teleprompt import BootstrapFewShotWithRandomSearch, COPRO, BayesianSignatureOptimizer

from brainstorm_module import BrainstormModule, OptimizedBrainstormModule
from evaluators import StoryIdeaEvaluator, create_evaluation_metric
from common import BrainstormRequest

class BrainstormExample(dspy.Example):
    """Example class for brainstorm training data"""
    def __init__(self, genre: str, platform: str, requirements_section: str = ""):
        super().__init__(
            genre=genre,
            platform=platform,
            requirements_section=requirements_section
        )
        # Mark input fields
        self.genre = genre
        self.platform = platform
        self.requirements_section = requirements_section

def create_training_examples() -> List[BrainstormExample]:
    """Create diverse training examples for optimization using real genre system"""
    examples = [
        # å¥³é¢‘ - çˆ±æƒ…ç±»
        BrainstormExample("ç”œå® ", "æŠ–éŸ³", "æµªæ¼«ç”œèœœçš„çˆ±æƒ…æ•…äº‹ï¼Œé€‚åˆå¹´è½»è§‚ä¼—"),
        BrainstormExample("è™æ‹", "å°çº¢ä¹¦", "å……æ»¡æ³¢æŠ˜ã€ç—›è‹¦å’Œæƒ…æ„ŸæŒ£æ‰çš„çˆ±æƒ…æ•…äº‹"),
        BrainstormExample("éœ¸æ€»", "å¿«æ‰‹", "é«˜å†·å‹éœ¸é“æ€»è£ï¼ŒèŠ‚å¥ç´§å‡‘"),
        
        # å¥³é¢‘ - è®¾å®šç±»
        BrainstormExample("ç©¿è¶Š", "æŠ–éŸ³", "èº«ç©¿æˆ–é­‚ç©¿ï¼Œå¤ä»£ç°ä»£èƒŒæ™¯éƒ½å¯"),
        BrainstormExample("é‡ç”Ÿ", "å°çº¢ä¹¦", "é‡ç”Ÿé¢˜æï¼Œå¤ä»‡æˆ–æ”¹å˜å‘½è¿"),
        BrainstormExample("é©¬ç”²", "å¿«æ‰‹", "å¤šé‡èº«ä»½è®¾å®šï¼Œåè½¬æƒŠå–œ"),
        BrainstormExample("æ›¿èº«", "æŠ–éŸ³", "çœŸå‡åƒé‡‘ï¼ŒåŒèƒèƒæ›¿æ¢"),
        
        # å¥³é¢‘ - å…¶ä»–ç±»å‹
        BrainstormExample("èŒå®", "å°çº¢ä¹¦", "å¯çˆ±èŒå¨ƒï¼Œæ¸©é¦¨å®¶åº­"),
        BrainstormExample("å›¢å® ", "å¿«æ‰‹", "è¢«å…¨å®¶å® çˆ±çš„è®¾å®š"),
        BrainstormExample("å¨±ä¹åœˆ", "æŠ–éŸ³", "å¨±ä¹åœˆèƒŒæ™¯ï¼Œæ˜æ˜Ÿç”Ÿæ´»"),
        
        # ç”·é¢‘ - è®¾å®šç±»
        BrainstormExample("ç„å¹»", "å¿«æ‰‹", "ä¿®ç‚¼æˆä»™ï¼Œå‡çº§æ‰“æ€ª"),
        BrainstormExample("æœ«ä¸–", "æŠ–éŸ³", "æœ«æ—¥æ±‚ç”Ÿï¼Œä¸§å°¸é¢˜æï¼Œåˆ¶ä½œæˆæœ¬å¯æ§"),
        
        # ç”·é¢‘ - é€†è¢­ç±»
        BrainstormExample("æˆ˜ç¥", "å°çº¢ä¹¦", "å¼ºè€…å½’æ¥ï¼Œå…µç‹é¢˜æ"),
        BrainstormExample("ç¥è±ª", "æŠ–éŸ³", "ä¸€å¤œæš´å¯Œï¼Œç‚¹çŸ³æˆé‡‘"),
        BrainstormExample("èµ˜å©¿", "å¿«æ‰‹", "èµ˜å©¿é€†è¢­ï¼Œæ‰®çŒªåƒè€è™"),
        BrainstormExample("é€†è¢­", "å°çº¢ä¹¦", "å°äººç‰©æˆé•¿ï¼Œé©¬ç”²å¤§ä½¬"),
        BrainstormExample("é‡‘æ‰‹æŒ‡", "æŠ–éŸ³", "è¶…èƒ½åŠ›ï¼Œç³»ç»Ÿé€‰ä¸­"),
        BrainstormExample("é«˜æ‰‹ä¸‹å±±", "å¿«æ‰‹", "éšä¸–é«˜æ‰‹é‡å‡ºæ±Ÿæ¹–"),
        
        # ç”·é¢‘ - å…¶ä»–ç±»å‹
        BrainstormExample("ç¥åŒ»", "å°çº¢ä¹¦", "åŒ»æœ¯é«˜è¶…ï¼Œæ‚¬å£¶æµä¸–"),
    ]
    
    return examples

def run_bootstrap_optimization():
    """Run bootstrap few-shot optimization"""
    print("ğŸš€ å¼€å§‹ Bootstrap Few-Shot ä¼˜åŒ–")
    print("=" * 50)
    
    # Create training examples
    train_examples = create_training_examples()
    print(f"åˆ›å»ºäº† {len(train_examples)} ä¸ªè®­ç»ƒæ ·ä¾‹")
    
    # Create evaluator and metric
    evaluator = StoryIdeaEvaluator()
    metric = create_evaluation_metric(evaluator)
    
    # Configure optimizer
    optimizer = BootstrapFewShotWithRandomSearch(
        metric=metric,
        num_candidate_programs=8,  # More candidates for better exploration
        max_bootstrapped_demos=3,  # More demonstrations
        num_threads=1,  # Keep single-threaded for stability
        max_rounds=2   # Multiple optimization rounds
    )
    
    print("é…ç½®ä¼˜åŒ–å™¨å®Œæˆï¼Œå¼€å§‹è®­ç»ƒ...")
    
    # Compile the module
    base_module = BrainstormModule()
    compiled_module = optimizer.compile(base_module, trainset=train_examples)
    
    print("âœ… Bootstrap ä¼˜åŒ–å®Œæˆ!")
    return compiled_module, train_examples

def run_copro_optimization():
    """Run COPRO (Collaborative Prompt Optimization)"""
    print("ğŸš€ å¼€å§‹ COPRO ä¼˜åŒ–")
    print("=" * 50)
    
    # Create training examples
    train_examples = create_training_examples()
    print(f"åˆ›å»ºäº† {len(train_examples)} ä¸ªè®­ç»ƒæ ·ä¾‹")
    
    # Create evaluator and metric
    evaluator = StoryIdeaEvaluator()
    metric = create_evaluation_metric(evaluator)
    
    # Configure COPRO optimizer
    optimizer = COPRO(
        metric=metric,
        breadth=10,    # Number of candidates to generate
        depth=3,       # Number of optimization iterations
        init_temperature=1.4  # Temperature for generation
    )
    
    print("é…ç½® COPRO ä¼˜åŒ–å™¨å®Œæˆï¼Œå¼€å§‹è®­ç»ƒ...")
    
    # Compile the module
    base_module = BrainstormModule()
    compiled_module = optimizer.compile(base_module, trainset=train_examples)
    
    print("âœ… COPRO ä¼˜åŒ–å®Œæˆ!")
    return compiled_module, train_examples

def evaluate_model_performance(module, test_examples: List[BrainstormExample], name: str):
    """Evaluate model performance on test examples"""
    print(f"\nğŸ“Š è¯„ä¼° {name} æ¨¡å‹æ€§èƒ½")
    print("-" * 40)
    
    evaluator = StoryIdeaEvaluator()
    total_scores = []
    
    for i, example in enumerate(test_examples[:5]):  # Test on first 5 examples
        try:
            request = BrainstormRequest(
                genre=example.genre,
                platform=example.platform,
                requirements_section=example.requirements_section
            )
            
            # Generate ideas
            ideas = module(request)
            
            # Evaluate
            result = evaluator.evaluate(ideas, request)
            total_scores.append(result.overall_score)
            
            print(f"  æ¡ˆä¾‹ {i+1} ({example.genre}): {result.overall_score:.1f}/10")
            
        except Exception as e:
            print(f"  æ¡ˆä¾‹ {i+1} è¯„ä¼°å¤±è´¥: {e}")
            continue
    
    if total_scores:
        avg_score = sum(total_scores) / len(total_scores)
        print(f"\n  å¹³å‡åˆ†æ•°: {avg_score:.1f}/10")
        return avg_score
    else:
        print("  æ— æœ‰æ•ˆè¯„ä¼°ç»“æœ")
        return 0.0

def save_optimized_model(module, name: str, score: float):
    """Save optimized model with MLflow"""
    with mlflow.start_run(run_name=f"optimized_brainstorm_{name}"):
        # Log parameters
        mlflow.log_param("optimizer_type", name)
        mlflow.log_param("model_type", "BrainstormModule")
        
        # Log metrics
        mlflow.log_metric("average_score", score)
        
        # Log model
        model_info = mlflow.dspy.log_model(
            module,
            artifact_path="model",
            input_example=BrainstormRequest(
                genre="éƒ½å¸‚çˆ±æƒ…",
                platform="æŠ–éŸ³"
            )
        )
        
        print(f"âœ… æ¨¡å‹å·²ä¿å­˜: {model_info.model_uri}")
        return model_info

def compare_models():
    """Compare different optimization approaches"""
    print("ğŸ†š æ¨¡å‹å¯¹æ¯”æµ‹è¯•")
    print("=" * 50)
    
    # Create test examples (separate from training)
    test_examples = [
        BrainstormExample("å…ˆå©šåçˆ±", "æŠ–éŸ³", "å¥‘çº¦å©šå§»ï¼Œæƒ…æ„ŸçœŸå®"),
        BrainstormExample("æ¶å¥³", "å°çº¢ä¹¦", "æ¶æ¯’å¥³é…é€†è¢­ï¼ŒåŒé‡äººæ ¼"),
        BrainstormExample("æ®‹ç–¾å¤§ä½¬", "å¿«æ‰‹", "æ®‹ç–¾å¤§ä½¬éšè—èº«ä»½"),
        BrainstormExample("åå®«", "æŠ–éŸ³", "åå®«äº‰æ–—ï¼Œæƒè°‹è®¾è®¡"),
        BrainstormExample("å¤ä»‡", "å°çº¢ä¹¦", "å¤ä»‡ä¸»é¢˜ï¼Œæƒ…èŠ‚ç´§å‡‘")
    ]
    
    results = {}
    
    # Test baseline model
    print("æµ‹è¯•åŸºç¡€æ¨¡å‹...")
    baseline_module = BrainstormModule()
    baseline_score = evaluate_model_performance(baseline_module, test_examples, "åŸºç¡€æ¨¡å‹")
    results["åŸºç¡€æ¨¡å‹"] = baseline_score
    
    # Test bootstrap optimized model
    try:
        print("\nè¿è¡Œ Bootstrap ä¼˜åŒ–...")
        bootstrap_module, _ = run_bootstrap_optimization()
        bootstrap_score = evaluate_model_performance(bootstrap_module, test_examples, "Bootstrapä¼˜åŒ–")
        results["Bootstrapä¼˜åŒ–"] = bootstrap_score
        
        # Save best bootstrap model
        save_optimized_model(bootstrap_module, "bootstrap", bootstrap_score)
        
    except Exception as e:
        print(f"Bootstrap ä¼˜åŒ–å¤±è´¥: {e}")
        results["Bootstrapä¼˜åŒ–"] = 0.0
    
    # Test COPRO optimized model
    try:
        print("\nè¿è¡Œ COPRO ä¼˜åŒ–...")
        copro_module, _ = run_copro_optimization()
        copro_score = evaluate_model_performance(copro_module, test_examples, "COPROä¼˜åŒ–")
        results["COPROä¼˜åŒ–"] = copro_score
        
        # Save COPRO model
        save_optimized_model(copro_module, "copro", copro_score)
        
    except Exception as e:
        print(f"COPRO ä¼˜åŒ–å¤±è´¥: {e}")
        results["COPROä¼˜åŒ–"] = 0.0
    
    # Display final results
    print("\nğŸ† æœ€ç»ˆå¯¹æ¯”ç»“æœ")
    print("=" * 50)
    for model_name, score in results.items():
        print(f"{model_name:15}: {score:.1f}/10")
    
    # Find best model
    best_model = max(results.items(), key=lambda x: x[1])
    print(f"\nğŸ¥‡ æœ€ä½³æ¨¡å‹: {best_model[0]} (å¾—åˆ†: {best_model[1]:.1f})")
    
    return results

def main():
    """Main optimization workflow"""
    print("ğŸ§ª æ•…äº‹åˆ›æ„ç”Ÿæˆä¼˜åŒ–ç³»ç»Ÿ")
    print("=" * 50)
    
    # Setup MLflow
    mlflow.set_experiment("Brainstorm_Optimization")
    mlflow.dspy.autolog()
    
    # Run comprehensive comparison
    results = compare_models()
    
    print("\nâœ… ä¼˜åŒ–æµç¨‹å®Œæˆ!")
    print("\nğŸ“ ä½¿ç”¨å»ºè®®:")
    print("1. æŸ¥çœ‹ MLflow UI äº†è§£è¯¦ç»†è®­ç»ƒè¿‡ç¨‹")
    print("2. é€‰æ‹©è¡¨ç°æœ€ä½³çš„æ¨¡å‹è¿›è¡Œéƒ¨ç½²")
    print("3. å¯ä»¥åŸºäºæœ€ä½³æ¨¡å‹ç»§ç»­è°ƒä¼˜å‚æ•°")

if __name__ == "__main__":
    main() 