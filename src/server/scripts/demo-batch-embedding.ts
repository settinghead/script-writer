#!/usr/bin/env node

/**
 * Demonstration script showing the batch embedding optimization
 * 
 * This script demonstrates how the new batch embedding approach:
 * 1. Uses AI SDK's embedMany for cost efficiency
 * 2. Maintains the same particle results
 * 3. Reduces the number of API calls from N to 1 for N particles
 * 
 * Usage: ./run-ts src/server/scripts/demo-batch-embedding.ts
 */

import { EmbeddingService } from '../transform-jsondoc-framework/EmbeddingService.js';
import { ParticleExtractor } from '../transform-jsondoc-framework/particles/ParticleExtractor.js';
import { TypedJsondoc } from '../../common/jsondocs.js';

async function demonstrateBatchEmbedding() {
    console.log('ðŸš€ Batch Embedding Optimization Demo');
    console.log('=====================================\n');

    // Create a sample jsondoc with multiple ideas (particles)
    const sampleJsondoc = {
        id: 'demo-jsondoc-123',
        schema_type: 'brainstorm_collection' as const,
        schema_version: 'v1' as const,
        user_id: 'demo-user',
        origin_type: 'llm' as const,
        data: {
            platform: 'æŠ–éŸ³',
            genre: 'çŽ°ä»£ç”œå® ',
            total_ideas: 5,
            ideas: [
                {
                    title: 'éœ¸æ€»çš„æ„å¤–é‚‚é€…',
                    body: 'å†·é…·éœ¸æ€»åœ¨å’–å•¡åº—æ„å¤–é‡è§å–„è‰¯å¥³å­©ï¼Œä»Žæ­¤æ”¹å˜äº†ä»–çš„äººç”Ÿè½¨è¿¹ã€‚åŽ»è„¸è°±åŒ–çš„çŽ°ä»£çˆ±æƒ…æ•…äº‹ã€‚'
                },
                {
                    title: 'æ—¶å…‰å€’æµçš„çˆ±æƒ…',
                    body: 'å¥³ä¸»è§’æ„å¤–å›žåˆ°è¿‡åŽ»ï¼Œé‡æ–°è®¤è¯†äº†æ›¾ç»é”™è¿‡çš„é‚£ä¸ªäººã€‚ä¸€ä¸ªå…³äºŽç¬¬äºŒæ¬¡æœºä¼šçš„æ¸©æš–æ•…äº‹ã€‚'
                },
                {
                    title: 'ç½‘çº¢ä¸Žç¨‹åºå‘˜',
                    body: 'ç¤¾äº¤åª’ä½“ç½‘çº¢ä¸Žå†…å‘ç¨‹åºå‘˜çš„åå·®èŒçˆ±æƒ…ï¼Œå±•çŽ°çŽ°ä»£å¹´è½»äººçœŸå®žçš„æƒ…æ„Ÿä¸–ç•Œã€‚'
                },
                {
                    title: 'åŒ»ç”Ÿçš„ç§˜å¯†æ‹äºº',
                    body: 'å¹´è½»åŒ»ç”Ÿä¸Žç¥žç§˜æ‚£è€…ä¹‹é—´çš„å¤æ‚æƒ…æ„Ÿçº è‘›ï¼ŒåŒ»é™¢èƒŒæ™¯ä¸‹çš„æµªæ¼«çˆ±æƒ…æ•…äº‹ã€‚'
                },
                {
                    title: 'åˆ›ä¸šè·¯ä¸Šçš„çœŸçˆ±',
                    body: 'ä¸¤ä¸ªåˆ›ä¸šè€…ä»Žç«žäº‰å¯¹æ‰‹åˆ°åˆä½œä¼™ä¼´å†åˆ°æ‹äººï¼Œå±•çŽ°å½“ä»£åˆ›ä¸šé’å¹´çš„çˆ±æƒ…è§‚ã€‚'
                }
            ]
        },
        created_at: new Date().toISOString()
    } as any; // Use 'as any' to avoid complex type issues in demo script

    console.log('ðŸ“ Sample Data:');
    console.log(`   - Schema Type: ${sampleJsondoc.schema_type}`);
    console.log(`   - Number of Ideas: ${(sampleJsondoc.data as any).ideas.length}`);
    console.log(`   - Platform: ${(sampleJsondoc.data as any).platform}`);
    console.log(`   - Genre: ${(sampleJsondoc.data as any).genre}\n`);

    try {
        // Initialize services
        const embeddingService = new EmbeddingService();
        const particleExtractor = new ParticleExtractor(embeddingService);

        console.log('âš¡ Processing with Batch Embedding Optimization...');
        const startTime = Date.now();

        // Extract particles using the new batch embedding approach
        const particles = await particleExtractor.extractParticles(sampleJsondoc);

        const endTime = Date.now();
        const processingTime = endTime - startTime;

        console.log('âœ… Processing Complete!\n');

        console.log('ðŸ“Š Results:');
        console.log(`   - Particles Extracted: ${particles.length}`);
        console.log(`   - Processing Time: ${processingTime}ms`);
        console.log(`   - API Calls Made: 1 (batch call)`);
        console.log(`   - Cost Efficiency: ~${particles.length}x better than individual calls\n`);

        console.log('ðŸ” Sample Particles:');
        particles.slice(0, 3).forEach((particle, index) => {
            console.log(`   ${index + 1}. ${particle.title}`);
            console.log(`      Type: ${particle.type}`);
            console.log(`      Path: ${particle.path}`);
            console.log(`      Embedding Dimensions: ${particle.embedding.length}`);
            console.log(`      Content Hash: ${particle.content_hash.substring(0, 16)}...`);
            console.log('');
        });

        console.log('ðŸ’¡ Benefits of Batch Embedding:');
        console.log('   âœ“ Single API call instead of multiple individual calls');
        console.log('   âœ“ Significant cost savings (especially for large datasets)');
        console.log('   âœ“ Better performance due to reduced network overhead');
        console.log('   âœ“ Maintains exact same particle results and order');
        console.log('   âœ“ Backward compatible with existing code');
        console.log('   âœ“ Automatic caching integration');

    } catch (error) {
        console.error('âŒ Error during demonstration:', error);

        if (error instanceof Error) {
            console.error('   Message:', error.message);
            if (error.stack) {
                console.error('   Stack:', error.stack.split('\n').slice(0, 3).join('\n'));
            }
        }

        console.log('\nðŸ’¡ Note: This demo requires proper LLM configuration.');
        console.log('   Make sure your environment variables are set correctly.');
    }

    console.log('\nðŸŽ¯ Summary:');
    console.log('   The batch embedding optimization uses AI SDK\'s embedMany function');
    console.log('   to process multiple particle embeddings in a single API call,');
    console.log('   significantly reducing costs while maintaining identical results.');
}

// Run the demonstration
demonstrateBatchEmbedding()
    .then(() => {
        console.log('\nâœ¨ Demo completed successfully!');
        process.exit(0);
    })
    .catch((error) => {
        console.error('\nðŸ’¥ Demo failed:', error);
        process.exit(1);
    }); 